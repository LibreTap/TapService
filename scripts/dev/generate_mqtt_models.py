#!/usr/bin/env python3
"""
Generate Pydantic models from MQTT Protocol JSON schemas.

This script fetches JSON schemas from the LibreTap/mqtt-protocol GitHub repository
and generates type-safe Pydantic models for runtime validation of MQTT messages.

Usage:
    uv run python scripts/dev/generate_mqtt_models.py

Output:
    tapservice/mqtt_protocol_models.py (auto-generated - do not edit manually)
"""
import subprocess
import sys
import tempfile
from pathlib import Path
from urllib.request import urlretrieve
from urllib.request import urlopen
import json


# GitHub URLs for schema files
SCHEMA_BASE_URL = "https://raw.githubusercontent.com/LibreTap/mqtt-protocol/main/schemas"


def get_schema_files_from_github() -> list[str]:
    """Fetch list of JSON schema files from the GitHub repository."""
    # GitHub API endpoint for directory contents
    api_url = "https://api.github.com/repos/LibreTap/mqtt-protocol/contents/schemas"
    
    try:
        with urlopen(api_url) as response:
            contents = json.loads(response.read())
            # Filter for .json files only
            return [item["name"] for item in contents if item["name"].endswith(".json")]
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not fetch schema list from GitHub API: {e}")
        print("   Falling back to directory scan after download...")
        return []


def download_schemas(temp_dir: Path) -> bool:
    """Download schema files from GitHub to temporary directory."""
    print("üì• Downloading schemas from LibreTap/mqtt-protocol repository...")
    
    schema_dir = temp_dir / "schemas"
    schema_dir.mkdir(parents=True, exist_ok=True)
    
    # Get list of schema files from GitHub
    schema_files = get_schema_files_from_github()
    
    if not schema_files:
        print("‚ö†Ô∏è  No schema files found via API, will rely on glob pattern after generation")
        return True  # Continue anyway, glob will find files if they exist
    
    print(f"   Found {len(schema_files)} schema file(s) to download")
    
    for schema_file in schema_files:
        url = f"{SCHEMA_BASE_URL}/{schema_file}"
        output_path = schema_dir / schema_file
        
        try:
            print(f"   Downloading {schema_file}...")
            urlretrieve(url, output_path)
            print(f"   ‚úÖ {schema_file}")
        except Exception as e:
            print(f"   ‚ùå Failed to download {schema_file}: {e}")
            return False
    
    return True


def combine_generated_files(generated_dir: Path, output_file: Path):
    """Combine all generated Python files into a single output file."""
    print("üì¶ Combining generated files...")
    
    # Collect all .py files
    py_files = sorted(generated_dir.glob("*.py"))
    
    if not py_files:
        print("‚ùå No Python files generated!")
        sys.exit(1)
    
    combined_content = []
    imports_seen = set()
    
    for py_file in py_files:
        print(f"   - {py_file.name}")
        content = py_file.read_text()
        
        # Extract imports and model definitions separately
        lines = content.split('\n')
        for line in lines:
            if line.startswith('from ') or line.startswith('import '):
                if line not in imports_seen:
                    imports_seen.add(line)
            elif line.strip():  # Non-empty, non-import line
                combined_content.append(line)
            elif combined_content and combined_content[-1]:  # Preserve blank lines between definitions
                combined_content.append(line)
    
    # Build final content: imports first, then models
    final_content = '\n'.join(sorted(imports_seen)) + '\n\n' + '\n'.join(combined_content)
    
    # Write to output file
    output_file.write_text(final_content)
    print(f"   ‚úÖ Combined into {output_file.name}")


def add_header_comment(output_file: Path):
    """Add a header comment to the generated file."""
    from datetime import datetime, UTC
    
    header = '''"""
AUTO-GENERATED FILE - DO NOT EDIT MANUALLY

This file is automatically generated from JSON schemas in the LibreTap/mqtt-protocol repository:
https://github.com/LibreTap/mqtt-protocol/tree/main/schemas

Generated by running: uv run python scripts/dev/generate_mqtt_models.py

To update these models:
1. Update JSON schemas in the mqtt-protocol repository
2. Run: uv run python scripts/dev/generate_mqtt_models.py
3. Commit the regenerated models

Last generated: {timestamp}
"""

'''
    
    # Read existing content
    content = output_file.read_text()
    
    # Add header if not already present
    if "AUTO-GENERATED FILE" not in content:
        timestamp = datetime.now(UTC).strftime("%Y-%m-%d %H:%M:%S UTC")
        header = header.format(timestamp=timestamp)
        output_file.write_text(header + content)


def main():
    # Paths - go from scripts/dev/ up to project root
    project_root = Path(__file__).parent.parent.parent
    output_file = project_root / "tapservice" / "mqtt_protocol_models.py"
    
    print(f"üìç Output file: {output_file}")
    
    # Create temporary directory for schemas
    with tempfile.TemporaryDirectory() as temp_dir_str:
        temp_dir = Path(temp_dir_str)
        
        # Download schemas
        if not download_schemas(temp_dir):
            print("\n‚ùå Failed to download schemas from GitHub")
            sys.exit(1)
        
        schema_dir = temp_dir / "schemas"
        
        # Find all JSON schema files
        schema_files = list(schema_dir.glob("*.json"))
        if not schema_files:
            print(f"‚ùå No JSON schema files found in {schema_dir}")
            sys.exit(1)
        
        print(f"\n‚úÖ Found {len(schema_files)} schema file(s):")
        for schema_file in schema_files:
            print(f"   - {schema_file.name}")
        
        # Generate models using datamodel-codegen via uv
        print("\nüîß Generating Pydantic models...")
        
        try:
            # Create temporary output directory for generated models
            temp_output_dir = temp_dir / "generated"
            temp_output_dir.mkdir(exist_ok=True)
            
            # Run datamodel-codegen via uv
            result = subprocess.run(
                [
                    "uv", "run", "datamodel-codegen",
                    "--input", str(schema_dir),
                    "--input-file-type", "jsonschema",
                    "--output", str(temp_output_dir),
                    "--output-model-type", "pydantic_v2.BaseModel",
                    "--use-standard-collections",
                    "--use-schema-description",
                    "--field-constraints",
                    "--use-annotated",
                ],
                check=True,
                capture_output=True,
                text=True
            )
            
            print("‚úÖ Model generation successful!")
            
            # Combine all generated files into one
            combine_generated_files(temp_output_dir, output_file)
            
            if result.stdout:
                print(f"   Output: {result.stdout}")
            
            # Add header comment to generated file
            add_header_comment(output_file)
            
            print(f"\n‚ú® Generated models saved to: {output_file}")
            print("\n‚ö†Ô∏è  DO NOT edit this file manually!")
            print("   To regenerate: uv run python scripts/dev/generate_mqtt_models.py")
            
        except subprocess.CalledProcessError as e:
            print("‚ùå Generation failed!")
            print(f"   Error: {e}")
            if e.stderr:
                print(f"   Details: {e.stderr}")
            sys.exit(1)
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
            sys.exit(1)


if __name__ == "__main__":
    main()
